{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Lab 07: Train a Neural Network (Solution)\n",
    "\n",
    "This is the completed solution notebook with all cells filled in and expected outputs documented.\n",
    "Use this as a reference if you get stuck on the main notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1: Why scikit-learn Isn't Enough\n",
    "\n",
    "We load CIFAR-10, flatten the images, and show that logistic regression gets ~40% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "device = torch.device('cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform\n",
    ")\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "CLASSES = ('airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "print(f\"Training images: {len(train_dataset)}\")\n",
    "print(f\"Test images:     {len(test_dataset)}\")\n",
    "print(f\"Image shape:     {train_dataset[0][0].shape}\")\n",
    "print(f\"Classes:         {CLASSES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 8, figsize=(16, 4))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    image, label = train_dataset[i]\n",
    "    image = image * 0.5 + 0.5\n",
    "    ax.imshow(image.permute(1, 2, 0).numpy())\n",
    "    ax.set_title(CLASSES[label], fontsize=9)\n",
    "    ax.axis('off')\n",
    "plt.suptitle('CIFAR-10 Sample Images', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "raw_transform = transforms.Compose([transforms.ToTensor()])\n",
    "raw_train = torchvision.datasets.CIFAR10(root='./data', train=True, download=False, transform=raw_transform)\n",
    "raw_test = torchvision.datasets.CIFAR10(root='./data', train=False, download=False, transform=raw_transform)\n",
    "\n",
    "n_train = 5000\n",
    "n_test = 1000\n",
    "\n",
    "X_train_flat = torch.stack([raw_train[i][0] for i in range(n_train)]).reshape(n_train, -1).numpy()\n",
    "y_train_flat = np.array([raw_train[i][1] for i in range(n_train)])\n",
    "X_test_flat = torch.stack([raw_test[i][0] for i in range(n_test)]).reshape(n_test, -1).numpy()\n",
    "y_test_flat = np.array([raw_test[i][1] for i in range(n_test)])\n",
    "\n",
    "print(f\"Flattened shape: {X_train_flat.shape}\")\n",
    "print(\"Training logistic regression on raw pixels...\")\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000, random_state=42, solver='saga')\n",
    "clf.fit(X_train_flat, y_train_flat)\n",
    "\n",
    "sklearn_acc = accuracy_score(y_test_flat, clf.predict(X_test_flat))\n",
    "print(f\"\\nscikit-learn accuracy on CIFAR-10: {sklearn_acc:.3f}\")\n",
    "print(f\"Conclusion: {sklearn_acc*100:.0f}% is better than random, but terrible.\")\n",
    "print(\"scikit-learn can't learn spatial patterns from raw pixels.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2: Your First Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class FeedforwardNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(3 * 32 * 32, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "model = FeedforwardNet().to(device)\n",
    "print(model)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3: The Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "model = FeedforwardNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'test_acc': [],\n",
    "    'batch_losses': [],\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        history['batch_losses'].append(loss.item())\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_acc = correct / total\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = outputs.max(1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    test_acc = test_correct / test_total\n",
    "    history['test_acc'].append(test_acc)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"Epoch {epoch+1:2d}/{NUM_EPOCHS} | \"\n",
    "          f\"Loss: {train_loss:.3f} | \"\n",
    "          f\"Train Acc: {train_acc*100:.1f}% | \"\n",
    "          f\"Test Acc: {test_acc*100:.1f}% | \"\n",
    "          f\"Time: {elapsed:.0f}s\")\n",
    "\n",
    "print(f\"\\nFinal test accuracy: {history['test_acc'][-1]*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4: Watch It Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "axes[0].plot(history['batch_losses'], alpha=0.3, color='blue', linewidth=0.5)\n",
    "window = 50\n",
    "if len(history['batch_losses']) > window:\n",
    "    smoothed = np.convolve(history['batch_losses'], np.ones(window)/window, mode='valid')\n",
    "    axes[0].plot(range(window-1, len(history['batch_losses'])), smoothed, color='red', linewidth=2, label='Smoothed')\n",
    "axes[0].set_xlabel('Batch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training Loss (per batch)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "epochs = range(1, NUM_EPOCHS + 1)\n",
    "axes[1].plot(epochs, history['train_loss'], 'o-', linewidth=2, markersize=6, label='Train Loss')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].set_title('Training Loss (per epoch)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[2].plot(epochs, [a*100 for a in history['train_acc']], 'o-', linewidth=2, markersize=6, label='Train Acc')\n",
    "axes[2].plot(epochs, [a*100 for a in history['test_acc']], 's-', linewidth=2, markersize=6, label='Test Acc')\n",
    "axes[2].axhline(y=sklearn_acc*100, color='gray', linestyle='--', alpha=0.5, label=f'sklearn ({sklearn_acc*100:.0f}%)')\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].set_ylabel('Accuracy (%)')\n",
    "axes[2].set_title('Train vs Test Accuracy')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "gap = history['train_acc'][-1] - history['test_acc'][-1]\n",
    "print(f\"Train-Test accuracy gap: {gap*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "fig, axes = plt.subplots(3, 8, figsize=(18, 7))\n",
    "\n",
    "test_iter = iter(test_loader)\n",
    "images, labels = next(test_iter)\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(images)\n",
    "    _, predicted = outputs.max(1)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i >= len(images):\n",
    "        break\n",
    "    img = images[i].cpu() * 0.5 + 0.5\n",
    "    ax.imshow(img.permute(1, 2, 0).numpy())\n",
    "    true_label = CLASSES[labels[i].item()]\n",
    "    pred_label = CLASSES[predicted[i].item()]\n",
    "    correct = labels[i].item() == predicted[i].item()\n",
    "    color = 'green' if correct else 'red'\n",
    "    ax.set_title(f\"P:{pred_label}\\nT:{true_label}\", fontsize=8, color=color)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('Predictions (green=correct, red=wrong)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 5: Improve with a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 8 * 8, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return self.classifier(x)\n",
    "\n",
    "\n",
    "cnn_model = SimpleCNN().to(device)\n",
    "print(cnn_model)\n",
    "cnn_params = sum(p.numel() for p in cnn_model.parameters())\n",
    "print(f\"\\nCNN parameters: {cnn_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = SimpleCNN().to(device)\n",
    "cnn_criterion = nn.CrossEntropyLoss()\n",
    "cnn_optimizer = torch.optim.SGD(cnn_model.parameters(), lr=0.01)\n",
    "\n",
    "cnn_history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'test_acc': [],\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    cnn_model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        cnn_optimizer.zero_grad()\n",
    "        outputs = cnn_model(images)\n",
    "        loss = cnn_criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        cnn_optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_acc = correct / total\n",
    "    cnn_history['train_loss'].append(train_loss)\n",
    "    cnn_history['train_acc'].append(train_acc)\n",
    "\n",
    "    cnn_model.eval()\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = cnn_model(images)\n",
    "            _, predicted = outputs.max(1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    test_acc = test_correct / test_total\n",
    "    cnn_history['test_acc'].append(test_acc)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"Epoch {epoch+1:2d}/{NUM_EPOCHS} | \"\n",
    "          f\"Loss: {train_loss:.3f} | \"\n",
    "          f\"Train Acc: {train_acc*100:.1f}% | \"\n",
    "          f\"Test Acc: {test_acc*100:.1f}% | \"\n",
    "          f\"Time: {elapsed:.0f}s\")\n",
    "\n",
    "print(f\"\\nCNN training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "epochs = range(1, NUM_EPOCHS + 1)\n",
    "\n",
    "axes[0].plot(epochs, [a*100 for a in history['test_acc']], 'o-', linewidth=2, label='Feedforward NN')\n",
    "axes[0].plot(epochs, [a*100 for a in cnn_history['test_acc']], 's-', linewidth=2, label='CNN')\n",
    "axes[0].axhline(y=sklearn_acc*100, color='gray', linestyle='--', alpha=0.7, label=f'sklearn LogReg ({sklearn_acc*100:.0f}%)')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Test Accuracy (%)')\n",
    "axes[0].set_title('Test Accuracy: sklearn vs Feedforward vs CNN')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(epochs, history['train_loss'], 'o-', linewidth=2, label='Feedforward NN')\n",
    "axes[1].plot(epochs, cnn_history['train_loss'], 's-', linewidth=2, label='CNN')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Training Loss')\n",
    "axes[1].set_title('Training Loss: Feedforward vs CNN')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Final test accuracy comparison:\")\n",
    "print(f\"  scikit-learn LogReg:  {sklearn_acc*100:.1f}%\")\n",
    "print(f\"  Feedforward NN:       {history['test_acc'][-1]*100:.1f}%\")\n",
    "print(f\"  CNN:                  {cnn_history['test_acc'][-1]*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 6: Checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "checkpoint_path = 'cnn_checkpoint.pt'\n",
    "\n",
    "checkpoint = {\n",
    "    'epoch': NUM_EPOCHS,\n",
    "    'model_state_dict': cnn_model.state_dict(),\n",
    "    'optimizer_state_dict': cnn_optimizer.state_dict(),\n",
    "    'train_loss': cnn_history['train_loss'][-1],\n",
    "    'test_acc': cnn_history['test_acc'][-1],\n",
    "    'history': cnn_history,\n",
    "}\n",
    "\n",
    "torch.save(checkpoint, checkpoint_path)\n",
    "\n",
    "size_mb = os.path.getsize(checkpoint_path) / (1024 * 1024)\n",
    "print(f\"Checkpoint saved: {size_mb:.2f} MB\")\n",
    "print(f\"Epoch: {checkpoint['epoch']}, Test acc: {checkpoint['test_acc']*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_checkpoint = torch.load(checkpoint_path, weights_only=False)\n",
    "\n",
    "restored_model = SimpleCNN().to(device)\n",
    "restored_optimizer = torch.optim.SGD(restored_model.parameters(), lr=0.01)\n",
    "\n",
    "restored_model.load_state_dict(loaded_checkpoint['model_state_dict'])\n",
    "restored_optimizer.load_state_dict(loaded_checkpoint['optimizer_state_dict'])\n",
    "resume_epoch = loaded_checkpoint['epoch']\n",
    "\n",
    "print(f\"Checkpoint loaded! Resuming from epoch {resume_epoch}.\")\n",
    "\n",
    "cnn_model.eval()\n",
    "restored_model.eval()\n",
    "\n",
    "test_images, test_labels = next(iter(test_loader))\n",
    "test_images = test_images.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    original_preds = cnn_model(test_images).argmax(dim=1)\n",
    "    restored_preds = restored_model(test_images).argmax(dim=1)\n",
    "\n",
    "match = (original_preds == restored_preds).all().item()\n",
    "print(f\"Predictions match: {match}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Resuming training from epoch {resume_epoch}...\")\n",
    "\n",
    "restored_model.train()\n",
    "for epoch in range(resume_epoch, resume_epoch + 2):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        restored_optimizer.zero_grad()\n",
    "        outputs = restored_model(images)\n",
    "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "        loss.backward()\n",
    "        restored_optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    restored_model.eval()\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, lbls in test_loader:\n",
    "            imgs, lbls = imgs.to(device), lbls.to(device)\n",
    "            outs = restored_model(imgs)\n",
    "            _, preds = outs.max(1)\n",
    "            test_total += lbls.size(0)\n",
    "            test_correct += preds.eq(lbls).sum().item()\n",
    "    restored_model.train()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | \"\n",
    "          f\"Loss: {running_loss/len(train_loader):.3f} | \"\n",
    "          f\"Train Acc: {100.*correct/total:.1f}% | \"\n",
    "          f\"Test Acc: {100.*test_correct/test_total:.1f}%\")\n",
    "\n",
    "print(\"\\nTraining resumed seamlessly from the checkpoint.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 7: Experiment Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def run_experiment(name, model_class, lr, epochs, train_loader, test_loader):\n",
    "    model = model_class().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "    start = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    train_correct = train_total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            _, predicted = model(images).max(1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    test_correct = test_total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            _, predicted = model(images).max(1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    return {\n",
    "        'experiment': name,\n",
    "        'architecture': model_class.__name__,\n",
    "        'lr': lr,\n",
    "        'epochs': epochs,\n",
    "        'params': sum(p.numel() for p in model.parameters()),\n",
    "        'train_acc': round(train_correct / train_total, 4),\n",
    "        'test_acc': round(test_correct / test_total, 4),\n",
    "        'train_time_s': round(time.time() - start, 1),\n",
    "    }\n",
    "\n",
    "\n",
    "experiments = []\n",
    "configs = [\n",
    "    ('ff_lr0.01_ep5', FeedforwardNet, 0.01, 5),\n",
    "    ('ff_lr0.05_ep5', FeedforwardNet, 0.05, 5),\n",
    "    ('cnn_lr0.01_ep5', SimpleCNN, 0.01, 5),\n",
    "    ('cnn_lr0.05_ep5', SimpleCNN, 0.05, 5),\n",
    "]\n",
    "\n",
    "for name, model_class, lr, epochs in configs:\n",
    "    print(f\"Running: {name}...\")\n",
    "    result = run_experiment(name, model_class, lr, epochs, train_loader, test_loader)\n",
    "    experiments.append(result)\n",
    "    print(f\"  -> test_acc={result['test_acc']*100:.1f}% in {result['train_time_s']}s\")\n",
    "\n",
    "print(f\"\\nAll {len(experiments)} experiments complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_path = 'experiment_log.json'\n",
    "with open(experiments_path, 'w') as f:\n",
    "    json.dump(experiments, f, indent=2)\n",
    "\n",
    "df = pd.DataFrame(experiments)\n",
    "df = df.sort_values('test_acc', ascending=False)\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"EXPERIMENT RESULTS (sorted by test accuracy)\")\n",
    "print(f\"{'='*80}\")\n",
    "print(df[['experiment', 'architecture', 'lr', 'epochs', 'params',\n",
    "          'train_acc', 'test_acc', 'train_time_s']].to_string(index=False))\n",
    "print(f\"\\nBest: {df.iloc[0]['experiment']} with {df.iloc[0]['test_acc']*100:.1f}% test accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "colors = ['#2196F3' if 'ff' in exp['experiment'] else '#FF9800' for exp in experiments]\n",
    "axes[0].barh(range(len(experiments)), [e['test_acc']*100 for e in experiments], color=colors)\n",
    "axes[0].set_yticks(range(len(experiments)))\n",
    "axes[0].set_yticklabels([e['experiment'] for e in experiments])\n",
    "axes[0].set_xlabel('Test Accuracy (%)')\n",
    "axes[0].set_title('Test Accuracy by Experiment')\n",
    "axes[0].axvline(x=sklearn_acc*100, color='gray', linestyle='--', alpha=0.5, label=f'sklearn ({sklearn_acc*100:.0f}%)')\n",
    "axes[0].legend()\n",
    "\n",
    "x_pos = range(len(experiments))\n",
    "width = 0.35\n",
    "axes[1].bar([x - width/2 for x in x_pos], [e['train_acc']*100 for e in experiments],\n",
    "           width, label='Train Acc', alpha=0.8)\n",
    "axes[1].bar([x + width/2 for x in x_pos], [e['test_acc']*100 for e in experiments],\n",
    "           width, label='Test Acc', alpha=0.8)\n",
    "axes[1].set_xticks(x_pos)\n",
    "axes[1].set_xticklabels([e['experiment'] for e in experiments], rotation=45, ha='right')\n",
    "axes[1].set_ylabel('Accuracy (%)')\n",
    "axes[1].set_title('Train vs Test Accuracy (gap = overfitting)')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in ['cnn_checkpoint.pt', 'experiment_log.json']:\n",
    "    if os.path.exists(path):\n",
    "        os.remove(path)\n",
    "        print(f\"Cleaned up {path}\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "| Concept | What You Learned |\n",
    "|---------|------------------|\n",
    "| **sklearn limits** | Flat feature vectors lose spatial structure -- bad for images |\n",
    "| **Feedforward NN** | Stacked linear layers with ReLU activations; learns intermediate features |\n",
    "| **Training loop** | forward -> loss -> backward -> step; the core of all deep learning |\n",
    "| **Overfitting** | Train accuracy rises, test accuracy plateaus; watch the gap |\n",
    "| **CNN** | Convolutional layers learn spatial patterns (edges, textures, shapes) |\n",
    "| **Checkpointing** | Save model + optimizer state to resume training after failures |\n",
    "| **Experiment tracking** | Log every run so you know what worked and what didn't |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbformat_minor": 4,
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
