{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Lab 07: Train a Neural Network\n",
    "\n",
    "You've been using scikit-learn for everything. It's great for tabular data and text.\n",
    "But try feeding raw pixels into logistic regression and watch it struggle.\n",
    "\n",
    "Images have **spatial structure** -- edges, textures, shapes -- that flat feature vectors\n",
    "can't capture. In this lab, you'll build your first neural network in PyTorch, train it\n",
    "on real images, see why CNNs beat feedforward networks, and learn to checkpoint your\n",
    "training so a crash doesn't erase hours of work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1: Why scikit-learn Isn't Enough\n",
    "\n",
    "Let's load the **CIFAR-10** dataset: 60,000 tiny (32x32) color images across 10 classes.\n",
    "We'll flatten each image into a vector of 3,072 numbers (32 x 32 x 3 channels) and\n",
    "feed it to scikit-learn's logistic regression.\n",
    "\n",
    "Spoiler: it will get around 40% accuracy. Better than random (10%), but terrible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Use CPU explicitly (no GPU needed for this lab)\n",
    "device = torch.device('cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load CIFAR-10\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform\n",
    ")\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "CLASSES = ('airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "print(f\"Training images: {len(train_dataset)}\")\n",
    "print(f\"Test images:     {len(test_dataset)}\")\n",
    "print(f\"Image shape:     {train_dataset[0][0].shape} (channels, height, width)\")\n",
    "print(f\"Classes:         {CLASSES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some examples\n",
    "fig, axes = plt.subplots(2, 8, figsize=(16, 4))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    image, label = train_dataset[i]\n",
    "    # Undo normalization for display\n",
    "    image = image * 0.5 + 0.5\n",
    "    ax.imshow(image.permute(1, 2, 0).numpy())\n",
    "    ax.set_title(CLASSES[label], fontsize=9)\n",
    "    ax.axis('off')\n",
    "plt.suptitle('CIFAR-10 Sample Images', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"These are 32x32 pixel images. Tiny, but enough to learn from.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now try scikit-learn: flatten pixels -> logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Use raw pixel values (unnormalized) for sklearn\n",
    "raw_transform = transforms.Compose([transforms.ToTensor()])\n",
    "raw_train = torchvision.datasets.CIFAR10(root='./data', train=True, download=False, transform=raw_transform)\n",
    "raw_test = torchvision.datasets.CIFAR10(root='./data', train=False, download=False, transform=raw_transform)\n",
    "\n",
    "# Flatten: (3, 32, 32) -> (3072,)\n",
    "# Use a subset for speed (full dataset would take too long with sklearn)\n",
    "n_train = 5000\n",
    "n_test = 1000\n",
    "\n",
    "X_train_flat = torch.stack([raw_train[i][0] for i in range(n_train)]).reshape(n_train, -1).numpy()\n",
    "y_train_flat = np.array([raw_train[i][1] for i in range(n_train)])\n",
    "X_test_flat = torch.stack([raw_test[i][0] for i in range(n_test)]).reshape(n_test, -1).numpy()\n",
    "y_test_flat = np.array([raw_test[i][1] for i in range(n_test)])\n",
    "\n",
    "print(f\"Flattened shape: {X_train_flat.shape} (samples, pixels)\")\n",
    "print(f\"Each image is now a flat vector of {X_train_flat.shape[1]} numbers.\")\n",
    "print(\"All spatial structure is destroyed.\")\n",
    "print(\"\\nTraining logistic regression on raw pixels...\")\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000, random_state=42, solver='saga')\n",
    "clf.fit(X_train_flat, y_train_flat)\n",
    "\n",
    "sklearn_acc = accuracy_score(y_test_flat, clf.predict(X_test_flat))\n",
    "print(f\"\\nscikit-learn accuracy on CIFAR-10: {sklearn_acc:.3f}\")\n",
    "print(f\"Random baseline (10 classes): 0.100\")\n",
    "print(f\"\\nConclusion: {sklearn_acc*100:.0f}% is better than random, but terrible.\")\n",
    "print(\"scikit-learn can't learn spatial patterns from raw pixels.\")\n",
    "print(\"That's what neural networks are for.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why did sklearn fail?** Logistic regression treats each pixel independently. It doesn't\n",
    "know that pixel (5,5) is *next to* pixel (5,6). It can't learn edges, textures, or shapes.\n",
    "It's like trying to understand a sentence by looking at each letter in isolation.\n",
    "\n",
    "Neural networks solve this by learning **intermediate representations** -- hidden layers\n",
    "that combine raw inputs into increasingly abstract features.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Your First Neural Network\n",
    "\n",
    "A **feedforward neural network** (also called a multi-layer perceptron) stacks multiple\n",
    "layers of linear transformations with non-linear activations between them.\n",
    "\n",
    "Our architecture:\n",
    "```\n",
    "Input (3072) -> Linear(512) -> ReLU -> Linear(256) -> ReLU -> Linear(10)\n",
    "```\n",
    "\n",
    "- **Input**: 3072 = 3 channels x 32 x 32 pixels (flattened)\n",
    "- **Hidden layer 1**: 512 neurons with ReLU activation\n",
    "- **Hidden layer 2**: 256 neurons with ReLU activation\n",
    "- **Output**: 10 neurons (one per class, no activation -- CrossEntropyLoss handles softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class FeedforwardNet(nn.Module):\n",
    "    \"\"\"A simple 3-layer feedforward neural network.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(3 * 32 * 32, 512),   # 3072 -> 512\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),             # 512 -> 256\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 10),              # 256 -> 10 (one per class)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)  # (batch, 3, 32, 32) -> (batch, 3072)\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "model = FeedforwardNet().to(device)\n",
    "print(model)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nTotal parameters:     {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"\\nThat's {total_params:,} numbers the network needs to learn.\")\n",
    "print(\"Compare this to logistic regression, which had ~30,000 coefficients.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what a forward pass looks like with random data\n",
    "dummy_input = torch.randn(4, 3, 32, 32).to(device)  # batch of 4 images\n",
    "dummy_output = model(dummy_input)\n",
    "\n",
    "print(f\"Input shape:  {dummy_input.shape}  (batch, channels, height, width)\")\n",
    "print(f\"Output shape: {dummy_output.shape}  (batch, num_classes)\")\n",
    "print(f\"\\nRaw outputs (logits) for first image:\")\n",
    "print(f\"  {dummy_output[0].detach().numpy()}\")\n",
    "print(f\"\\nThese are raw scores, not probabilities. The highest score is the prediction.\")\n",
    "print(f\"Predicted class: {CLASSES[dummy_output[0].argmax().item()]}\")\n",
    "print(f\"\\n(Random weights = random predictions. We haven't trained yet.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3: The Training Loop\n",
    "\n",
    "The training loop is the heart of deep learning. Every iteration does four things:\n",
    "\n",
    "1. **Forward pass**: Feed data through the network to get predictions\n",
    "2. **Compute loss**: Measure how wrong the predictions are (CrossEntropyLoss)\n",
    "3. **Backward pass**: Compute gradients (how to adjust each parameter to reduce loss)\n",
    "4. **Optimizer step**: Update parameters using the gradients\n",
    "\n",
    "```\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in dataloader:\n",
    "        optimizer.zero_grad()          # Clear old gradients\n",
    "        outputs = model(batch.images)  # Forward pass\n",
    "        loss = criterion(outputs, batch.labels)  # Compute loss\n",
    "        loss.backward()                # Backward pass (compute gradients)\n",
    "        optimizer.step()               # Update weights\n",
    "```\n",
    "\n",
    "That's it. Every neural network ever trained follows this pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Create data loaders (batch the data)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "print(f\"Training batches: {len(train_loader)} (each with up to 64 images)\")\n",
    "print(f\"Test batches:     {len(test_loader)}\")\n",
    "\n",
    "# Reset model with fresh weights\n",
    "model = FeedforwardNet().to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "print(f\"\\nLoss function: CrossEntropyLoss (combines LogSoftmax + NLLLoss)\")\n",
    "print(f\"Optimizer:     SGD with lr=0.01\")\n",
    "print(f\"\\nReady to train!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The training loop -- this is where the magic happens\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "# Track metrics for plotting later\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'test_acc': [],\n",
    "    'batch_losses': [],\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # --- Training phase ---\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()               # 1. Clear gradients\n",
    "        outputs = model(images)             # 2. Forward pass\n",
    "        loss = criterion(outputs, labels)   # 3. Compute loss\n",
    "        loss.backward()                     # 4. Backward pass\n",
    "        optimizer.step()                    # 5. Update weights\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        history['batch_losses'].append(loss.item())\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_acc = correct / total\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "\n",
    "    # --- Evaluation phase ---\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "\n",
    "    with torch.no_grad():  # No gradients needed for evaluation\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = outputs.max(1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    test_acc = test_correct / test_total\n",
    "    history['test_acc'].append(test_acc)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"Epoch {epoch+1:2d}/{NUM_EPOCHS} | \"\n",
    "          f\"Loss: {train_loss:.3f} | \"\n",
    "          f\"Train Acc: {train_acc*100:.1f}% | \"\n",
    "          f\"Test Acc: {test_acc*100:.1f}% | \"\n",
    "          f\"Time: {elapsed:.0f}s\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\nTraining complete in {total_time:.0f} seconds.\")\n",
    "print(f\"Final test accuracy: {history['test_acc'][-1]*100:.1f}%\")\n",
    "print(f\"\\nCompare to scikit-learn's {sklearn_acc*100:.0f}% -- already better!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What just happened?** The network started with random weights and gradually learned to\n",
    "classify images by adjusting its ~1.7 million parameters through gradient descent.\n",
    "Each epoch, loss went down and accuracy went up.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Watch It Learn\n",
    "\n",
    "Numbers are good, but plots are better. Let's visualize the training process\n",
    "and look for signs of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Plot 1: Batch loss curve (every batch)\n",
    "axes[0].plot(history['batch_losses'], alpha=0.3, color='blue', linewidth=0.5)\n",
    "# Add smoothed version\n",
    "window = 50\n",
    "if len(history['batch_losses']) > window:\n",
    "    smoothed = np.convolve(history['batch_losses'], np.ones(window)/window, mode='valid')\n",
    "    axes[0].plot(range(window-1, len(history['batch_losses'])), smoothed, color='red', linewidth=2, label='Smoothed')\n",
    "axes[0].set_xlabel('Batch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training Loss (per batch)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Epoch loss\n",
    "epochs = range(1, NUM_EPOCHS + 1)\n",
    "axes[1].plot(epochs, history['train_loss'], 'o-', linewidth=2, markersize=6, label='Train Loss')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].set_title('Training Loss (per epoch)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Train vs Test accuracy\n",
    "axes[2].plot(epochs, [a*100 for a in history['train_acc']], 'o-', linewidth=2, markersize=6, label='Train Acc')\n",
    "axes[2].plot(epochs, [a*100 for a in history['test_acc']], 's-', linewidth=2, markersize=6, label='Test Acc')\n",
    "axes[2].axhline(y=sklearn_acc*100, color='gray', linestyle='--', alpha=0.5, label=f'sklearn ({sklearn_acc*100:.0f}%)')\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].set_ylabel('Accuracy (%)')\n",
    "axes[2].set_title('Train vs Test Accuracy')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "gap = history['train_acc'][-1] - history['test_acc'][-1]\n",
    "print(f\"Train-Test accuracy gap: {gap*100:.1f}%\")\n",
    "if gap > 0.1:\n",
    "    print(\"The gap is growing -- this is overfitting.\")\n",
    "    print(\"Train accuracy keeps climbing but test accuracy plateaus.\")\n",
    "else:\n",
    "    print(\"Gap is small -- not much overfitting yet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some predictions\n",
    "model.eval()\n",
    "fig, axes = plt.subplots(3, 8, figsize=(18, 7))\n",
    "\n",
    "# Get a batch of test images\n",
    "test_iter = iter(test_loader)\n",
    "images, labels = next(test_iter)\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(images)\n",
    "    _, predicted = outputs.max(1)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i >= len(images):\n",
    "        break\n",
    "    # Undo normalization\n",
    "    img = images[i].cpu() * 0.5 + 0.5\n",
    "    ax.imshow(img.permute(1, 2, 0).numpy())\n",
    "\n",
    "    true_label = CLASSES[labels[i].item()]\n",
    "    pred_label = CLASSES[predicted[i].item()]\n",
    "    correct = labels[i].item() == predicted[i].item()\n",
    "\n",
    "    color = 'green' if correct else 'red'\n",
    "    ax.set_title(f\"P:{pred_label}\\nT:{true_label}\", fontsize=8, color=color)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('Predictions (green=correct, red=wrong)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key observations:**\n",
    "- The loss curve shows training is working (loss decreasing)\n",
    "- If train accuracy keeps rising but test accuracy plateaus or drops, that's **overfitting**\n",
    "- The feedforward network gets ~50% on CIFAR-10. Decent for a first attempt, but we can do much better.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Improve with a CNN\n",
    "\n",
    "The feedforward network flattens the image and ignores spatial relationships.\n",
    "A **Convolutional Neural Network (CNN)** preserves spatial structure by:\n",
    "\n",
    "1. **Convolving** small filters (3x3) across the image to detect local patterns\n",
    "2. **Pooling** to reduce resolution while keeping important features\n",
    "3. **Stacking** conv layers so later layers combine simple features into complex ones\n",
    "\n",
    "```\n",
    "Layer 1: edges, color blobs\n",
    "Layer 2: textures, simple shapes (wheels, eyes)\n",
    "Layer 3+: complex patterns (faces, cars)\n",
    "```\n",
    "\n",
    "Our CNN architecture:\n",
    "```\n",
    "Conv2d(3->32) -> ReLU -> MaxPool -> Conv2d(32->64) -> ReLU -> MaxPool -> FC(64*8*8->256) -> FC(256->10)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    \"\"\"A simple CNN with 2 convolutional layers and 2 fully-connected layers.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Convolutional layers (preserve spatial structure)\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),   # (3, 32, 32) -> (32, 32, 32)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),                            # (32, 32, 32) -> (32, 16, 16)\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),  # (32, 16, 16) -> (64, 16, 16)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),                            # (64, 16, 16) -> (64, 8, 8)\n",
    "        )\n",
    "        # Fully-connected layers (classify from features)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),                                  # (64, 8, 8) -> (4096)\n",
    "            nn.Linear(64 * 8 * 8, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return self.classifier(x)\n",
    "\n",
    "\n",
    "cnn_model = SimpleCNN().to(device)\n",
    "print(cnn_model)\n",
    "\n",
    "cnn_params = sum(p.numel() for p in cnn_model.parameters())\n",
    "ff_params = sum(p.numel() for p in FeedforwardNet().parameters())\n",
    "print(f\"\\nCNN parameters:         {cnn_params:,}\")\n",
    "print(f\"Feedforward parameters: {ff_params:,}\")\n",
    "print(f\"\\nThe CNN has fewer parameters but is smarter about how it uses them.\")\n",
    "print(f\"Convolutions share weights across spatial positions -- this is the key insight.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the CNN with the same setup\n",
    "cnn_model = SimpleCNN().to(device)\n",
    "cnn_criterion = nn.CrossEntropyLoss()\n",
    "cnn_optimizer = torch.optim.SGD(cnn_model.parameters(), lr=0.01)\n",
    "\n",
    "cnn_history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'test_acc': [],\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # Training\n",
    "    cnn_model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        cnn_optimizer.zero_grad()\n",
    "        outputs = cnn_model(images)\n",
    "        loss = cnn_criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        cnn_optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_acc = correct / total\n",
    "    cnn_history['train_loss'].append(train_loss)\n",
    "    cnn_history['train_acc'].append(train_acc)\n",
    "\n",
    "    # Evaluation\n",
    "    cnn_model.eval()\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = cnn_model(images)\n",
    "            _, predicted = outputs.max(1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    test_acc = test_correct / test_total\n",
    "    cnn_history['test_acc'].append(test_acc)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"Epoch {epoch+1:2d}/{NUM_EPOCHS} | \"\n",
    "          f\"Loss: {train_loss:.3f} | \"\n",
    "          f\"Train Acc: {train_acc*100:.1f}% | \"\n",
    "          f\"Test Acc: {test_acc*100:.1f}% | \"\n",
    "          f\"Time: {elapsed:.0f}s\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\nCNN training complete in {total_time:.0f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all three approaches\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "epochs = range(1, NUM_EPOCHS + 1)\n",
    "\n",
    "# Test accuracy comparison\n",
    "axes[0].plot(epochs, [a*100 for a in history['test_acc']], 'o-', linewidth=2, label='Feedforward NN')\n",
    "axes[0].plot(epochs, [a*100 for a in cnn_history['test_acc']], 's-', linewidth=2, label='CNN')\n",
    "axes[0].axhline(y=sklearn_acc*100, color='gray', linestyle='--', alpha=0.7, label=f'sklearn LogReg ({sklearn_acc*100:.0f}%)')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Test Accuracy (%)')\n",
    "axes[0].set_title('Test Accuracy: sklearn vs Feedforward vs CNN')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Loss comparison\n",
    "axes[1].plot(epochs, history['train_loss'], 'o-', linewidth=2, label='Feedforward NN')\n",
    "axes[1].plot(epochs, cnn_history['train_loss'], 's-', linewidth=2, label='CNN')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Training Loss')\n",
    "axes[1].set_title('Training Loss: Feedforward vs CNN')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nFinal test accuracy comparison:\")\n",
    "print(f\"  scikit-learn LogReg:  {sklearn_acc*100:.1f}%\")\n",
    "print(f\"  Feedforward NN:       {history['test_acc'][-1]*100:.1f}%\")\n",
    "print(f\"  CNN:                  {cnn_history['test_acc'][-1]*100:.1f}%\")\n",
    "print(f\"\\nCNNs learn spatial features -- edges, textures, shapes.\")\n",
    "print(f\"That's why they're better at images.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why does the CNN win?**\n",
    "\n",
    "- **Weight sharing**: The same 3x3 filter is applied everywhere -- it doesn't need to relearn \"edge\" at each position\n",
    "- **Local patterns**: Conv filters look at small neighborhoods of pixels, capturing spatial relationships\n",
    "- **Hierarchical features**: Stacked conv layers build simple features into complex ones\n",
    "\n",
    "The feedforward net treats each pixel independently. The CNN understands that pixels near each other matter together.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Checkpointing\n",
    "\n",
    "Training a neural network can take hours, days, or weeks. If your process crashes at\n",
    "epoch 47 of 50, you don't want to start over.\n",
    "\n",
    "**Checkpointing** saves the training state to disk so you can resume from where you left off.\n",
    "This is the same concept as **write-ahead logging** in databases -- you persist state so\n",
    "you can recover from failures.\n",
    "\n",
    "A checkpoint contains:\n",
    "- Model weights (`state_dict`)\n",
    "- Optimizer state (momentum, learning rate schedule, etc.)\n",
    "- Current epoch and loss\n",
    "- Anything else you need to resume exactly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Save a checkpoint\n",
    "checkpoint_path = 'cnn_checkpoint.pt'\n",
    "\n",
    "checkpoint = {\n",
    "    'epoch': NUM_EPOCHS,\n",
    "    'model_state_dict': cnn_model.state_dict(),\n",
    "    'optimizer_state_dict': cnn_optimizer.state_dict(),\n",
    "    'train_loss': cnn_history['train_loss'][-1],\n",
    "    'test_acc': cnn_history['test_acc'][-1],\n",
    "    'history': cnn_history,\n",
    "}\n",
    "\n",
    "torch.save(checkpoint, checkpoint_path)\n",
    "\n",
    "size_mb = os.path.getsize(checkpoint_path) / (1024 * 1024)\n",
    "print(f\"Checkpoint saved to: {checkpoint_path}\")\n",
    "print(f\"File size: {size_mb:.2f} MB\")\n",
    "print(f\"Contents:\")\n",
    "print(f\"  - epoch: {checkpoint['epoch']}\")\n",
    "print(f\"  - train_loss: {checkpoint['train_loss']:.4f}\")\n",
    "print(f\"  - test_acc: {checkpoint['test_acc']*100:.1f}%\")\n",
    "print(f\"  - model_state_dict: {len(checkpoint['model_state_dict'])} parameter tensors\")\n",
    "print(f\"  - optimizer_state_dict: optimizer momentum + state\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the checkpoint into a fresh model\n",
    "loaded_checkpoint = torch.load(checkpoint_path, weights_only=False)\n",
    "\n",
    "# Create a fresh model and optimizer\n",
    "restored_model = SimpleCNN().to(device)\n",
    "restored_optimizer = torch.optim.SGD(restored_model.parameters(), lr=0.01)\n",
    "\n",
    "# Load saved state\n",
    "restored_model.load_state_dict(loaded_checkpoint['model_state_dict'])\n",
    "restored_optimizer.load_state_dict(loaded_checkpoint['optimizer_state_dict'])\n",
    "resume_epoch = loaded_checkpoint['epoch']\n",
    "\n",
    "print(f\"Checkpoint loaded! Resuming from epoch {resume_epoch}.\")\n",
    "print(f\"Previous test accuracy: {loaded_checkpoint['test_acc']*100:.1f}%\")\n",
    "\n",
    "# Verify the restored model produces the same predictions\n",
    "cnn_model.eval()\n",
    "restored_model.eval()\n",
    "\n",
    "test_images, test_labels = next(iter(test_loader))\n",
    "test_images = test_images.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    original_preds = cnn_model(test_images).argmax(dim=1)\n",
    "    restored_preds = restored_model(test_images).argmax(dim=1)\n",
    "\n",
    "match = (original_preds == restored_preds).all().item()\n",
    "print(f\"\\nPredictions match original model: {match}\")\n",
    "print(\"The checkpoint captures the model exactly -- no information lost.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue training from the checkpoint for 2 more epochs\n",
    "print(f\"Resuming training from epoch {resume_epoch}...\")\n",
    "\n",
    "restored_model.train()\n",
    "for epoch in range(resume_epoch, resume_epoch + 2):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        restored_optimizer.zero_grad()\n",
    "        outputs = restored_model(images)\n",
    "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "        loss.backward()\n",
    "        restored_optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    # Quick test eval\n",
    "    restored_model.eval()\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, lbls in test_loader:\n",
    "            imgs, lbls = imgs.to(device), lbls.to(device)\n",
    "            outs = restored_model(imgs)\n",
    "            _, preds = outs.max(1)\n",
    "            test_total += lbls.size(0)\n",
    "            test_correct += preds.eq(lbls).sum().item()\n",
    "    restored_model.train()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | \"\n",
    "          f\"Loss: {running_loss/len(train_loader):.3f} | \"\n",
    "          f\"Train Acc: {100.*correct/total:.1f}% | \"\n",
    "          f\"Test Acc: {100.*test_correct/test_total:.1f}%\")\n",
    "\n",
    "print(\"\\nTraining resumed seamlessly from the checkpoint.\")\n",
    "print(\"This is fault tolerance for training -- same concept as write-ahead logging.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpointing best practices:**\n",
    "- Save after every epoch (or every N batches for long epochs)\n",
    "- Save the optimizer state too, not just the model (momentum matters!)\n",
    "- Keep the last K checkpoints and delete older ones to save disk space\n",
    "- In production, save to networked storage so you can resume on a different machine\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7: Experiment Tracking (Simple)\n",
    "\n",
    "When you start experimenting with different architectures, learning rates, and other\n",
    "hyperparameters, you need to track what you tried and what worked.\n",
    "\n",
    "For now, we'll use a simple JSON log file. After 20+ experiments, you'll want MLflow\n",
    "or Weights & Biases. But the principle is the same: **log everything, compare later.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def run_experiment(name, model_class, lr, epochs, train_loader, test_loader):\n",
    "    \"\"\"Run a training experiment and return results.\"\"\"\n",
    "    model = model_class().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # Train\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluate\n",
    "    model.eval()\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            _, predicted = model(images).max(1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            _, predicted = model(images).max(1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    train_time = time.time() - start\n",
    "    n_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "    result = {\n",
    "        'experiment': name,\n",
    "        'architecture': model_class.__name__,\n",
    "        'lr': lr,\n",
    "        'epochs': epochs,\n",
    "        'params': n_params,\n",
    "        'train_acc': round(train_correct / train_total, 4),\n",
    "        'test_acc': round(test_correct / test_total, 4),\n",
    "        'train_time_s': round(train_time, 1),\n",
    "    }\n",
    "    return result\n",
    "\n",
    "\n",
    "print(\"Experiment runner ready. Let's compare configurations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run several experiments\n",
    "experiments = []\n",
    "\n",
    "configs = [\n",
    "    ('ff_lr0.01_ep5', FeedforwardNet, 0.01, 5),\n",
    "    ('ff_lr0.05_ep5', FeedforwardNet, 0.05, 5),\n",
    "    ('cnn_lr0.01_ep5', SimpleCNN, 0.01, 5),\n",
    "    ('cnn_lr0.05_ep5', SimpleCNN, 0.05, 5),\n",
    "]\n",
    "\n",
    "for name, model_class, lr, epochs in configs:\n",
    "    print(f\"Running: {name}...\")\n",
    "    result = run_experiment(name, model_class, lr, epochs, train_loader, test_loader)\n",
    "    experiments.append(result)\n",
    "    print(f\"  -> test_acc={result['test_acc']*100:.1f}% in {result['train_time_s']}s\")\n",
    "\n",
    "print(f\"\\nAll {len(experiments)} experiments complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save experiments to JSON\n",
    "experiments_path = 'experiment_log.json'\n",
    "with open(experiments_path, 'w') as f:\n",
    "    json.dump(experiments, f, indent=2)\n",
    "print(f\"Experiments saved to {experiments_path}\")\n",
    "\n",
    "# Load and compare in a DataFrame\n",
    "df = pd.DataFrame(experiments)\n",
    "df = df.sort_values('test_acc', ascending=False)\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"EXPERIMENT RESULTS (sorted by test accuracy)\")\n",
    "print(f\"{'='*80}\")\n",
    "print(df[['experiment', 'architecture', 'lr', 'epochs', 'params',\n",
    "          'train_acc', 'test_acc', 'train_time_s']].to_string(index=False))\n",
    "print(f\"\\nBest experiment: {df.iloc[0]['experiment']} with {df.iloc[0]['test_acc']*100:.1f}% test accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize experiment comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar chart of test accuracies\n",
    "colors = ['#2196F3' if 'ff' in exp['experiment'] else '#FF9800' for exp in experiments]\n",
    "axes[0].barh(range(len(experiments)), [e['test_acc']*100 for e in experiments], color=colors)\n",
    "axes[0].set_yticks(range(len(experiments)))\n",
    "axes[0].set_yticklabels([e['experiment'] for e in experiments])\n",
    "axes[0].set_xlabel('Test Accuracy (%)')\n",
    "axes[0].set_title('Test Accuracy by Experiment')\n",
    "axes[0].axvline(x=sklearn_acc*100, color='gray', linestyle='--', alpha=0.5, label=f'sklearn ({sklearn_acc*100:.0f}%)')\n",
    "axes[0].legend()\n",
    "\n",
    "# Train vs test accuracy (overfitting check)\n",
    "x_pos = range(len(experiments))\n",
    "width = 0.35\n",
    "axes[1].bar([x - width/2 for x in x_pos], [e['train_acc']*100 for e in experiments],\n",
    "           width, label='Train Acc', alpha=0.8)\n",
    "axes[1].bar([x + width/2 for x in x_pos], [e['test_acc']*100 for e in experiments],\n",
    "           width, label='Test Acc', alpha=0.8)\n",
    "axes[1].set_xticks(x_pos)\n",
    "axes[1].set_xticklabels([e['experiment'] for e in experiments], rotation=45, ha='right')\n",
    "axes[1].set_ylabel('Accuracy (%)')\n",
    "axes[1].set_title('Train vs Test Accuracy (gap = overfitting)')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Blue = Feedforward, Orange = CNN\")\n",
    "print(\"The gap between train and test bars shows overfitting.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up checkpoint and experiment files\n",
    "for path in ['cnn_checkpoint.pt', 'experiment_log.json']:\n",
    "    if os.path.exists(path):\n",
    "        os.remove(path)\n",
    "        print(f\"Cleaned up {path}\")\n",
    "\n",
    "print(\"\\nDone! All temporary files removed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "You just built and trained neural networks from scratch. Here's what you now know:\n",
    "\n",
    "| Concept | What You Learned |\n",
    "|---------|------------------|\n",
    "| **sklearn limits** | Flat feature vectors lose spatial structure -- bad for images |\n",
    "| **Feedforward NN** | Stacked linear layers with ReLU activations; learns intermediate features |\n",
    "| **Training loop** | forward -> loss -> backward -> step; the core of all deep learning |\n",
    "| **Overfitting** | Train accuracy rises, test accuracy plateaus; watch the gap |\n",
    "| **CNN** | Convolutional layers learn spatial patterns (edges, textures, shapes) |\n",
    "| **Checkpointing** | Save model + optimizer state to resume training after failures |\n",
    "| **Experiment tracking** | Log every run so you know what worked and what didn't |\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "In **ML Lab 08**, you'll move from training models to running pre-trained large language\n",
    "models (LLMs) on your own machine."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbformat_minor": 4,
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
