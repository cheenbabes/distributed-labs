{
  "nbformat": 4,
  "nbformat_minor": 4,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbformat_minor": 4,
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ML Lab 05: Drift Analysis Notebook\n",
        "\n",
        "This notebook queries Prometheus metrics collected during the drift simulation\n",
        "and performs post-hoc analysis to understand how drift manifests in model behavior.\n",
        "\n",
        "**Prerequisites:** Run the drift simulator first (`docker compose --profile simulator up drift-simulator`)\n",
        "and ensure Prometheus is running at http://localhost:9090."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 1: Query Prometheus Metrics\n",
        "\n",
        "We'll query the Prometheus HTTP API to pull time-series data for our drift metrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "PROMETHEUS_URL = \"http://localhost:9090\"\n",
        "\n",
        "\n",
        "def query_prometheus_range(query: str, start: str = \"now-15m\", end: str = \"now\", step: str = \"15s\") -> pd.DataFrame:\n",
        "    \"\"\"Query Prometheus range API and return a DataFrame.\"\"\"\n",
        "    # Convert relative times to absolute\n",
        "    now = datetime.now()\n",
        "    if start == \"now-15m\":\n",
        "        start_ts = (now - timedelta(minutes=15)).timestamp()\n",
        "    elif start == \"now-30m\":\n",
        "        start_ts = (now - timedelta(minutes=30)).timestamp()\n",
        "    elif start == \"now-1h\":\n",
        "        start_ts = (now - timedelta(hours=1)).timestamp()\n",
        "    else:\n",
        "        start_ts = float(start)\n",
        "    end_ts = now.timestamp() if end == \"now\" else float(end)\n",
        "\n",
        "    resp = requests.get(\n",
        "        f\"{PROMETHEUS_URL}/api/v1/query_range\",\n",
        "        params={\"query\": query, \"start\": start_ts, \"end\": end_ts, \"step\": step},\n",
        "    )\n",
        "    resp.raise_for_status()\n",
        "    data = resp.json()\n",
        "\n",
        "    if data[\"status\"] != \"success\" or not data[\"data\"][\"result\"]:\n",
        "        print(f\"No data returned for query: {query}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    frames = []\n",
        "    for series in data[\"data\"][\"result\"]:\n",
        "        metric_label = series[\"metric\"].get(\"__name__\", \"\")\n",
        "        label = \", \".join(f\"{k}={v}\" for k, v in series[\"metric\"].items() if k != \"__name__\")\n",
        "        name = f\"{metric_label} ({label})\" if label else metric_label\n",
        "\n",
        "        values = series[\"values\"]\n",
        "        timestamps = [datetime.fromtimestamp(float(v[0])) for v in values]\n",
        "        vals = [float(v[1]) for v in values]\n",
        "        df = pd.DataFrame({\"timestamp\": timestamps, name: vals})\n",
        "        df.set_index(\"timestamp\", inplace=True)\n",
        "        frames.append(df)\n",
        "\n",
        "    if frames:\n",
        "        return pd.concat(frames, axis=1)\n",
        "    return pd.DataFrame()\n",
        "\n",
        "\n",
        "print(\"Prometheus query helper loaded.\")\n",
        "print(f\"Querying: {PROMETHEUS_URL}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 2: Confidence Distribution Over Time\n",
        "\n",
        "Prediction confidence is one of the strongest drift signals. When the model receives\n",
        "out-of-distribution data, it becomes less certain about its predictions, and the average\n",
        "confidence drops."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Query average confidence over time\n",
        "confidence_query = (\n",
        "    \"rate(model_prediction_confidence_sum[1m]) / \"\n",
        "    \"rate(model_prediction_confidence_count[1m])\"\n",
        ")\n",
        "\n",
        "df_confidence = query_prometheus_range(confidence_query, start=\"now-30m\")\n",
        "\n",
        "if not df_confidence.empty:\n",
        "    fig, ax = plt.subplots(figsize=(12, 5))\n",
        "    df_confidence.plot(ax=ax)\n",
        "    ax.set_title(\"Average Prediction Confidence Over Time\", fontsize=14)\n",
        "    ax.set_ylabel(\"Confidence\")\n",
        "    ax.set_xlabel(\"Time\")\n",
        "    ax.set_ylim(0.4, 1.0)\n",
        "    ax.axhline(y=0.75, color=\"red\", linestyle=\"--\", alpha=0.7, label=\"Alert threshold (0.75)\")\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\nConfidence Statistics:\")\n",
        "    print(df_confidence.describe())\n",
        "else:\n",
        "    print(\"No confidence data available. Run the drift simulator first.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 3: Text Length Distribution Shifts\n",
        "\n",
        "Changes in input text length can indicate distribution shift. Different categories of\n",
        "text (politics vs. baseball) may have characteristically different lengths."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Query average text length over time\n",
        "text_length_query = (\n",
        "    \"rate(model_input_text_length_sum[1m]) / \"\n",
        "    \"rate(model_input_text_length_count[1m])\"\n",
        ")\n",
        "\n",
        "df_text_length = query_prometheus_range(text_length_query, start=\"now-30m\")\n",
        "\n",
        "if not df_text_length.empty:\n",
        "    fig, ax = plt.subplots(figsize=(12, 5))\n",
        "    df_text_length.plot(ax=ax, color=\"purple\")\n",
        "    ax.set_title(\"Average Input Text Length Over Time\", fontsize=14)\n",
        "    ax.set_ylabel(\"Characters\")\n",
        "    ax.set_xlabel(\"Time\")\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\nText Length Statistics:\")\n",
        "    print(df_text_length.describe())\n",
        "else:\n",
        "    print(\"No text length data available. Run the drift simulator first.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 4: Population Stability Index (PSI)\n",
        "\n",
        "PSI measures how much a distribution has shifted compared to a reference distribution.\n",
        "It is commonly used in production ML systems to quantify drift.\n",
        "\n",
        "**Interpretation:**\n",
        "- PSI < 0.1: No significant shift\n",
        "- 0.1 <= PSI < 0.2: Moderate shift (investigate)\n",
        "- PSI >= 0.2: Significant shift (action required)\n",
        "\n",
        "We'll compute PSI on the confidence distribution, comparing the first window (baseline)\n",
        "to subsequent windows."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def calculate_psi(reference: np.ndarray, current: np.ndarray, bins: int = 10) -> float:\n",
        "    \"\"\"Calculate Population Stability Index between two distributions.\n",
        "\n",
        "    PSI = sum( (current_pct - reference_pct) * ln(current_pct / reference_pct) )\n",
        "\n",
        "    Args:\n",
        "        reference: Array of values from the reference (baseline) distribution.\n",
        "        current: Array of values from the current distribution.\n",
        "        bins: Number of bins for discretization.\n",
        "\n",
        "    Returns:\n",
        "        PSI value (float). Higher = more drift.\n",
        "    \"\"\"\n",
        "    # Create bins from the reference distribution\n",
        "    breakpoints = np.linspace(\n",
        "        min(reference.min(), current.min()),\n",
        "        max(reference.max(), current.max()),\n",
        "        bins + 1,\n",
        "    )\n",
        "\n",
        "    # Compute bin proportions\n",
        "    ref_counts = np.histogram(reference, bins=breakpoints)[0]\n",
        "    cur_counts = np.histogram(current, bins=breakpoints)[0]\n",
        "\n",
        "    # Convert to proportions with small epsilon to avoid division by zero\n",
        "    eps = 1e-6\n",
        "    ref_pct = (ref_counts + eps) / (ref_counts.sum() + eps * bins)\n",
        "    cur_pct = (cur_counts + eps) / (cur_counts.sum() + eps * bins)\n",
        "\n",
        "    # PSI formula\n",
        "    psi = np.sum((cur_pct - ref_pct) * np.log(cur_pct / ref_pct))\n",
        "    return float(psi)\n",
        "\n",
        "\n",
        "# Demonstrate PSI with synthetic data\n",
        "np.random.seed(42)\n",
        "\n",
        "# Simulate baseline confidence (high, centered around 0.92)\n",
        "baseline_confidence = np.random.beta(20, 2, size=200)  # skewed high\n",
        "\n",
        "# Simulate drifted confidence (lower, more spread)\n",
        "slight_drift = np.random.beta(10, 3, size=200)\n",
        "moderate_drift = np.random.beta(5, 4, size=200)\n",
        "heavy_drift = np.random.beta(3, 5, size=200)\n",
        "\n",
        "# Calculate PSI for each phase\n",
        "psi_slight = calculate_psi(baseline_confidence, slight_drift)\n",
        "psi_moderate = calculate_psi(baseline_confidence, moderate_drift)\n",
        "psi_heavy = calculate_psi(baseline_confidence, heavy_drift)\n",
        "\n",
        "print(\"PSI Values (Confidence Distribution):\")\n",
        "print(f\"  Baseline vs Baseline:  {calculate_psi(baseline_confidence, baseline_confidence):.4f} (should be ~0)\")\n",
        "print(f\"  Baseline vs Slight:    {psi_slight:.4f}\")\n",
        "print(f\"  Baseline vs Moderate:  {psi_moderate:.4f}\")\n",
        "print(f\"  Baseline vs Heavy:     {psi_heavy:.4f}\")\n",
        "print()\n",
        "print(\"Interpretation:\")\n",
        "print(f\"  PSI < 0.1  = No significant shift\")\n",
        "print(f\"  PSI 0.1-0.2 = Moderate shift (investigate)\")\n",
        "print(f\"  PSI >= 0.2  = Significant shift (action required)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Visualize the distributions and PSI\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "distributions = [\n",
        "    (\"Baseline\", baseline_confidence, 0.0),\n",
        "    (\"Slight Drift\", slight_drift, psi_slight),\n",
        "    (\"Moderate Drift\", moderate_drift, psi_moderate),\n",
        "    (\"Heavy Drift\", heavy_drift, psi_heavy),\n",
        "]\n",
        "\n",
        "for ax, (name, dist, psi) in zip(axes.flat, distributions):\n",
        "    ax.hist(baseline_confidence, bins=20, alpha=0.5, label=\"Baseline\", color=\"blue\", density=True)\n",
        "    ax.hist(dist, bins=20, alpha=0.5, label=name, color=\"orange\", density=True)\n",
        "    ax.set_title(f\"{name} (PSI = {psi:.4f})\", fontsize=12)\n",
        "    ax.set_xlabel(\"Confidence\")\n",
        "    ax.set_ylabel(\"Density\")\n",
        "    ax.legend()\n",
        "    ax.set_xlim(0, 1)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "    # Color code the PSI\n",
        "    if psi < 0.1:\n",
        "        ax.set_facecolor(\"#f0fff0\")  # light green\n",
        "    elif psi < 0.2:\n",
        "        ax.set_facecolor(\"#fffff0\")  # light yellow\n",
        "    else:\n",
        "        ax.set_facecolor(\"#fff0f0\")  # light red\n",
        "\n",
        "plt.suptitle(\"Confidence Distribution Shift (PSI Analysis)\", fontsize=14, fontweight=\"bold\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 5: Building a Drift Alert Threshold\n",
        "\n",
        "Now let's combine our drift signals into a practical alerting strategy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Query entropy over time\n",
        "entropy_query = (\n",
        "    \"rate(model_prediction_entropy_sum[1m]) / \"\n",
        "    \"rate(model_prediction_entropy_count[1m])\"\n",
        ")\n",
        "\n",
        "df_entropy = query_prometheus_range(entropy_query, start=\"now-30m\")\n",
        "\n",
        "if not df_entropy.empty and not df_confidence.empty:\n",
        "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 8), sharex=True)\n",
        "\n",
        "    # Confidence panel\n",
        "    df_confidence.plot(ax=ax1, color=\"green\")\n",
        "    ax1.axhline(y=0.75, color=\"red\", linestyle=\"--\", alpha=0.7, label=\"Alert: Confidence < 0.75\")\n",
        "    ax1.set_title(\"Drift Signal: Confidence\", fontsize=12)\n",
        "    ax1.set_ylabel(\"Confidence\")\n",
        "    ax1.set_ylim(0.4, 1.0)\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "\n",
        "    # Fill red where confidence below threshold\n",
        "    for col in df_confidence.columns:\n",
        "        ax1.fill_between(\n",
        "            df_confidence.index,\n",
        "            df_confidence[col],\n",
        "            0.75,\n",
        "            where=df_confidence[col] < 0.75,\n",
        "            alpha=0.3,\n",
        "            color=\"red\",\n",
        "        )\n",
        "\n",
        "    # Entropy panel\n",
        "    df_entropy.plot(ax=ax2, color=\"orange\")\n",
        "    ax2.axhline(y=0.6, color=\"red\", linestyle=\"--\", alpha=0.7, label=\"Alert: Entropy > 0.6\")\n",
        "    ax2.set_title(\"Drift Signal: Entropy\", fontsize=12)\n",
        "    ax2.set_ylabel(\"Entropy (bits)\")\n",
        "    ax2.set_xlabel(\"Time\")\n",
        "    ax2.set_ylim(0, 1.0)\n",
        "    ax2.legend()\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "\n",
        "    # Fill red where entropy above threshold\n",
        "    for col in df_entropy.columns:\n",
        "        ax2.fill_between(\n",
        "            df_entropy.index,\n",
        "            df_entropy[col],\n",
        "            0.6,\n",
        "            where=df_entropy[col] > 0.6,\n",
        "            alpha=0.3,\n",
        "            color=\"red\",\n",
        "        )\n",
        "\n",
        "    plt.suptitle(\"Drift Detection: Combined Signals with Alert Thresholds\", fontsize=14, fontweight=\"bold\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Insufficient data. Run the drift simulator and try again.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Summary: Recommended alert rules\n",
        "print(\"=\" * 60)\n",
        "print(\"RECOMMENDED DRIFT ALERT RULES\")\n",
        "print(\"=\" * 60)\n",
        "print()\n",
        "print(\"1. Confidence Drop Alert\")\n",
        "print(\"   PromQL: rate(model_prediction_confidence_sum[5m])\")\n",
        "print(\"           / rate(model_prediction_confidence_count[5m]) < 0.75\")\n",
        "print(\"   Severity: Warning\")\n",
        "print(\"   Action: Investigate input data distribution\")\n",
        "print()\n",
        "print(\"2. High Entropy Alert\")\n",
        "print(\"   PromQL: rate(model_prediction_entropy_sum[5m])\")\n",
        "print(\"           / rate(model_prediction_entropy_count[5m]) > 0.6\")\n",
        "print(\"   Severity: Warning\")\n",
        "print(\"   Action: Check for out-of-distribution inputs\")\n",
        "print()\n",
        "print(\"3. PSI Threshold (batch job)\")\n",
        "print(\"   Calculate PSI on confidence distributions\")\n",
        "print(\"   every hour, comparing to the training baseline.\")\n",
        "print(\"   PSI > 0.2 => Significant drift, consider retraining\")\n",
        "print()\n",
        "print(\"4. Combined Alert (most robust)\")\n",
        "print(\"   Fire when BOTH confidence < 0.75 AND entropy > 0.6\")\n",
        "print(\"   for more than 5 minutes. This reduces false positives.\")\n",
        "print(\"=\" * 60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Takeaways\n",
        "\n",
        "1. **Confidence drops when models see unfamiliar data** -- this is the simplest and most reliable drift signal.\n",
        "2. **Entropy increases with uncertainty** -- for binary classification, max entropy is 1.0 (coin flip).\n",
        "3. **PSI gives you a single number** -- use it to quantify drift and set thresholds for automated alerts.\n",
        "4. **Combine multiple signals** -- no single metric is perfect; using confidence + entropy together reduces false positives.\n",
        "5. **Detection is not remediation** -- once you detect drift, you still need a plan: retrain, fall back to a simpler model, or flag for human review."
      ]
    }
  ]
}
