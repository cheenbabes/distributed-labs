# Demo Runbook: Deploy a Model as an API

This runbook contains all commands for the video demo. If you have the [Runme extension](https://runme.dev) installed in VS Code, you can run each command block directly with the play button.

---

## Pre-Demo Setup

### Check Docker is running

```bash {"name": "check-docker"}
docker info > /dev/null 2>&1 && echo "✓ Docker is running" || echo "✗ Docker is not running"
```

### Clean any previous lab state

```bash {"name": "clean-previous"}
docker compose down -v 2>/dev/null || true
```

---

## Part 1: Start the Lab

### Build and start all services

```bash {"name": "start-lab"}
docker compose up --build -d
```

### Wait for services to be ready

```bash {"name": "wait-healthy"}
echo "Waiting for model to train and API to start (~30-60 seconds)..."
sleep 30
docker compose ps
```

### Verify the model API is ready

```bash {"name": "check-ready"}
curl -s http://localhost:8000/health | python3 -m json.tool
```

---

## Part 2: Explore the API

### Check health endpoint

```bash {"name": "health-check"}
echo "=== Health Check ==="
curl -s http://localhost:8000/health | python3 -m json.tool
```

### Check readiness endpoint

```bash {"name": "ready-check"}
echo "=== Readiness Check ==="
curl -s http://localhost:8000/ready | python3 -m json.tool
```

### Show the API docs URL

```bash {"name": "show-docs"}
echo "Open the interactive API docs:"
echo ""
echo "  http://localhost:8000/docs"
echo ""
echo "This is auto-generated by FastAPI from the Pydantic models."
```

---

## Part 3: Make Predictions

### Predict on space text

```bash {"name": "predict-space"}
echo "=== Space Text ==="
curl -s -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"text": "NASA launched a new satellite to study the atmosphere of Mars"}' | python3 -m json.tool
```

### Predict on baseball text

```bash {"name": "predict-baseball"}
echo "=== Baseball Text ==="
curl -s -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"text": "The pitcher threw a fastball and struck out the batter in the ninth inning"}' | python3 -m json.tool
```

### Predict on ambiguous text

```bash {"name": "predict-ambiguous"}
echo "=== Ambiguous Text ==="
curl -s -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"text": "The team launched the ball into orbit around the stadium"}' | python3 -m json.tool
```

---

## Part 4: Check the Metrics

### View raw Prometheus metrics

```bash {"name": "raw-metrics"}
echo "=== Prometheus Metrics ==="
curl -s http://localhost:8000/metrics | head -50
```

### Show Prometheus targets

```bash {"name": "show-prometheus"}
echo "Open Prometheus to see the scrape target:"
echo ""
echo "  http://localhost:9090/targets"
echo ""
echo "The model-api target should show UP."
```

---

## Part 5: Watch the Dashboard

### Show Grafana URL

```bash {"name": "show-grafana"}
echo "Open Grafana dashboard:"
echo ""
echo "  http://localhost:3001"
echo ""
echo "Login: admin / admin"
echo "Navigate to: Dashboards > Model API Dashboard"
```

### Send a burst of predictions to populate the dashboard

```bash {"name": "burst-predictions"}
echo "Sending 50 predictions to populate the dashboard..."
for i in $(seq 1 25); do
  curl -s -X POST http://localhost:8000/predict \
    -H "Content-Type: application/json" \
    -d '{"text": "The pitcher threw a fastball and struck out the batter"}' > /dev/null
  curl -s -X POST http://localhost:8000/predict \
    -H "Content-Type: application/json" \
    -d '{"text": "NASA launched a new Mars rover to explore the red planet"}' > /dev/null
done
echo "Done! Check the Grafana dashboard now."
```

---

## Part 6: Load Test

### Send 200 rapid predictions

```bash {"name": "load-test"}
echo "Sending 200 predictions..."
TEXTS=(
  "The pitcher threw a fastball and struck out the batter"
  "NASA launched a new satellite to study Mars"
  "The home run in the bottom of the ninth sealed the championship"
  "The telescope captured images of a distant galaxy cluster"
  "The shortstop made an incredible diving catch"
  "SpaceX successfully landed the booster rocket"
)
for i in $(seq 1 200); do
  TEXT="${TEXTS[$((RANDOM % ${#TEXTS[@]}))]}"
  curl -s -X POST http://localhost:8000/predict \
    -H "Content-Type: application/json" \
    -d "{\"text\": \"$TEXT\"}" > /dev/null &
  # Limit parallelism
  if (( i % 10 == 0 )); then
    wait
    echo "  Sent $i predictions..."
  fi
done
wait
echo "Done! Check Grafana for latency and throughput graphs."
```

---

## Cleanup

### Stop all services

```bash {"name": "cleanup"}
docker compose down -v
echo "✓ Lab cleaned up"
```

---

## Troubleshooting Commands

### Check model-api logs

```bash {"name": "logs-api"}
docker compose logs model-api --tail=50
```

### Check Prometheus logs

```bash {"name": "logs-prometheus"}
docker compose logs prometheus --tail=50
```

### Check Grafana logs

```bash {"name": "logs-grafana"}
docker compose logs grafana --tail=50
```

### Check resource usage

```bash {"name": "resource-usage"}
docker stats --no-stream
```

### Restart the model API

```bash {"name": "restart-api"}
docker compose restart model-api
```

---

## Quick Reference

| Action | Command |
|--------|---------|
| Start lab | `docker compose up --build -d` |
| Stop lab | `docker compose down -v` |
| View API logs | `docker compose logs model-api` |
| Test prediction | `curl -X POST http://localhost:8000/predict -H "Content-Type: application/json" -d '{"text": "test"}'` |
| Model API | http://localhost:8000 |
| API Docs | http://localhost:8000/docs |
| Prometheus | http://localhost:9090 |
| Grafana | http://localhost:3001 (admin/admin) |
